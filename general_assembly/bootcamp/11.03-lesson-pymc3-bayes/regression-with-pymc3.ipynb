{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Bayesian Regression with `pymc3`\n",
    "\n",
    "_Authors: Kiefer Katovich (SF)_\n",
    "\n",
    "---\n",
    "\n",
    "### Learning Objectives\n",
    "- Describe how to use pymc3 to fit Bayesian estimation models\n",
    "- Plot and interpret the results of pymc3 models\n",
    "- Construct a Bayesian regression using pymc3\n",
    "- Use the patsy-style formula syntax to build a pymc3 regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson Guide\n",
    "- [Introduction](#intro)\n",
    "- [Enter `pymc3`](#pymc3)\n",
    "- [Load the Starcraft data](#data)\n",
    "- [Alternative to t-testing using Bayesian estimation](#ttest)\n",
    "    - [Get the APM values for 19 and 26 year olds](#load)\n",
    "    - [Perform a Frequentist t-test of the mean APM difference between groups.](#freq-ttest)\n",
    "    - [Set up a Bayesian model with priors on the mean APMs](#priors)\n",
    "    - [Construct the prior distributions on the means](#construct-priors)\n",
    "    - [Construct the prior distributions on the standard deviations](#std-priors)\n",
    "    - [Set up the APM distributions for the two groups](#apm-dists)\n",
    "    - [Tracking additional metrics](#metrics)\n",
    "    - [Fitting the `pymc3` model](#fit)\n",
    "    - [Plotting the posteriors and metric distributions](#plotting)\n",
    "- [Bayesian regression with `pymc3`](#reg)\n",
    "    - [Set up variables to perform an age vs. APM regression](#age-vs-apm)\n",
    "    - [Set up the Bayesian regression model](#bayes-model)\n",
    "    - [Plot the posteriors using `pm.traceplot`](#traceplot)\n",
    "- [Using a patsy-style formula to specify a `pymc3` model](#formula)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## Introduction\n",
    "---\n",
    "\n",
    "With `pymc3` we can perform the Bayesian counterparts of Frequentist models we have studied. In this codealong lesson we will start incrementally: first by repeating the Beta-Binomial model from yesterday, then replacing the Frequentist t-test with Bayesian estimation and finally performing a Bayesian regression with a single predictor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pymc3'></a>\n",
    "## Enter `pymc3`\n",
    "---\n",
    "\n",
    "The `pymc3` is the Bayesian modeling package we will be using. It is a powerful and flexible architecture for performing a huge variety of Bayesian analyses. We will only be scratching the surface today.\n",
    "\n",
    "> **Note:** There is also `pymc` (or pymc2) which has a different syntax. pymc2 is (in my opinion) harder for beginners to Bayesian statistics to understand; pymc3 bridges the gap better for those who are more familiar with constructing models using Frequentist style models/syntax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the website subscription example.  Say from previous experience, I observed 345 subscriptions out of a total of 1000 visits.  My new data shows 40 subscriptions out of 100 visits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='data'></a>\n",
    "### Load the Starcraft dataset\n",
    "---\n",
    "\n",
    "You may be familiar with this dataset. It has records of different player statistics in competitive Starcraft. There are a variety of columns that are described in detail within the `description.txt` file contained inside the `./datasets/` folder.\n",
    "\n",
    "For the examples in this lab, I will be using APM (actions per minute) and Age, but I in the following lab you will get the chance to look at other variables as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='reg'></a>\n",
    "## Bayesian regression with `pymc3`\n",
    "---\n",
    "\n",
    "With `pymc3`, the sky is the limit. Let's move on to something a little more complicated: Bayesian regressions.\n",
    "\n",
    "> *Note: [This example is modeled after the generalized linear model (GLM) instructions in the pymc3 documentation.](http://pymc-devs.github.io/pymc3/notebooks/GLM-linear.html)*\n",
    "\n",
    "What are the benefits to taking a Bayesian approach to regression modeling? Just like in our estimation of means per group, when we perform regression with Bayesian statistics we will get out posterior *distributions* on our intercept and coefficients. \n",
    "\n",
    "This is a big difference from the point estimates coming out of the Frequentist regression: not only do we have the most likely value for the coefficients (the MAP estimates), we can see the range of possibilities given our prior and observed data. \n",
    "\n",
    "---\n",
    "\n",
    "<a id='age-vs-apm'></a>\n",
    "### Set up variables to perform an age vs. APM regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot out the age vs. apm values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='bayes-model'></a>\n",
    "### Setting up the Bayesian regression model\n",
    "\n",
    "Remember regression?\n",
    "\n",
    "## $$y = \\beta_0 + \\beta_1 x + \\epsilon$$\n",
    "\n",
    "From a statistical perspective, $\\beta_0$, $\\beta_1$ and $\\epsilon$ are random variables.\n",
    "\n",
    "For the sake of simplicity, let's assume that they are _uniform_ random variables.  This will be our prior belief, that will be updated based on data!\n",
    "\n",
    "## $$\\beta_0 \\sim Uniform(-200, 200)$$\n",
    "\n",
    "## $$\\beta_1 \\sim Uniform(-10000, 10000)$$\n",
    "\n",
    "## $$\\epsilon \\sim Uniform(0.0001, 1000)$$\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Like before, we will construct our model with the `with pm.Model() ...` syntax. \n",
    "\n",
    "We have three prior distributions in this case that will be updated to posteriors given our observed data:\n",
    "\n",
    "1. `apm_std`: which will be our prior belief about the standard deviation of APM values. In this case I am setting it to be uniform (uninformative) between `0.0001`, and `1000.`\n",
    "- `intercept`: a uniform distribution for the range of possible values of the intercept.\n",
    "- `age_beta`: a uniform distribution for the range of possible values of the age coefficient.\n",
    "\n",
    "We set up a `likelihood` distribution that is also normal, representing the distribution of the data (APM) given our predictor. The mean of the likelihood is defined like a regression formula: our intercept distribution plus the age values times our age beta distribution. We give the `apm_std` uniform prior as the standard deviation. Lastly, the observed values, or data, will be the APM values.\n",
    "\n",
    "What will happen here as we sample from the posterior is that more likely values (as defined by the `mu=` regression-style definition) will be \"visited\" more often. The intercept and age_beta distributions will have more values visited in places where they result in higher likelihood estimates.\n",
    "\n",
    "`pm.find_MAP()` tries to find good starting values for our sampling procedure so that we don't have to run it for as many iterations to get a good posterior representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='traceplot'></a>\n",
    "### Plot the posteriors using `pm.traceplot`\n",
    "\n",
    "The traceplot function can also plot our posteriors, as well as a graph of the actual traces for each distribution. These traces represent the points visited by the sampling algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='formula'></a>\n",
    "## Setting up a model using a patsy-style formula\n",
    "---\n",
    "\n",
    "`pymc3` also provides a convenience function `pm.glm.glm(...` which takes a patsy-style formula definition and the dataframe, then automatically constructs the distributions required to solve the Bayesian regression. Pretty nice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lastly, you can plot out different possible regression lines with `pm.glm.plot_posterior_predictive`.**\n",
    "\n",
    "This function takes:\n",
    "\n",
    "- the trace (MCMC samples)\n",
    "- the number of samples you want to draw out and plot\n",
    "- an `lm=` argument that will be a function defining how the regression line will be fit using an x value and the sample\n",
    "- an `eval=` argument that will be the x-values `lm` is evaluated over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
