{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Bayesian Estimationwith `pymc3`\n",
    "\n",
    "_Authors: Kiefer Katovich (SF)_\n",
    "\n",
    "---\n",
    "\n",
    "### Learning Objectives\n",
    "- Describe how to use pymc3 to fit Bayesian estimation models\n",
    "- Run the Bayesian alternative to a t-test using pymc3\n",
    "- Plot and interpret the results of pymc3 models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson Guide\n",
    "- [Introduction](#intro)\n",
    "- [Load the Starcraft data](#data)\n",
    "- [Alternative to t-testing using Bayesian estimation](#ttest)\n",
    "    - [Get the APM values for 19 and 26 year olds](#load)\n",
    "    - [Perform a Frequentist t-test of the mean APM difference between groups.](#freq-ttest)\n",
    "    - [Set up a Bayesian model with priors on the mean APMs](#priors)\n",
    "    - [Construct the prior distributions on the means](#construct-priors)\n",
    "    - [Construct the prior distributions on the standard deviations](#std-priors)\n",
    "    - [Set up the APM distributions for the two groups](#apm-dists)\n",
    "    - [Tracking additional metrics](#metrics)\n",
    "    - [Fitting the `pymc3` model](#fit)\n",
    "    - [Plotting the posteriors and metric distributions](#plotting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## Introduction\n",
    "---\n",
    "\n",
    "With `pymc3` we can perform the Bayesian counterparts of Frequentist models we have studied. In this codealong lesson we will start incrementally: first by repeating the Beta-Binomial model from yesterday, then replacing the Frequentist t-test with Bayesian estimation and finally performing a Bayesian regression with a single predictor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='data'></a>\n",
    "### Load the Starcraft dataset\n",
    "---\n",
    "\n",
    "You may be familiar with this dataset. It has records of different player statistics in competitive Starcraft. There are a variety of columns that are described in detail within the `description.txt` file contained inside the `./datasets/` folder.\n",
    "\n",
    "For the examples in this lab, I will be using APM (actions per minute) and Age, but I in the following lab you will get the chance to look at other variables as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ttest'></a>\n",
    "## Alternative to t-testing using Bayesian estimation\n",
    "---\n",
    "\n",
    "[This example is adapted from the documentation here.](http://pymc-devs.github.io/pymc3/notebooks/BEST.html) \n",
    "\n",
    "> *Note: In that example the Student t distribution is used instead of the normal distribution like I use below. This is more appropriate, but more complicated due to the parameterization of the t-distribution. If you're feeling bold try doing this with the t-distribution like in the documentation!\n",
    "\n",
    "In the following code, I will be using Bayesian posterior estimation to look at the difference in APM between 19 year old players and 26 year old players.\n",
    "\n",
    "### The Frequentist strategy\n",
    "In Frequentist statistics, calculating the mean difference between groups is typically done with a t-test. In a t-test we state a null hypothesis (H0) that there is no diffference between groups, then evaluate the probability that we could have gotten this data when the null hypothesis is true.\n",
    "\n",
    "The de-facto standard for statistically comparing two (or more) samples is to use a statistical test. This involves expressing a null hypothesis, which typically claims that there is no difference between the groups, and using a chosen test statistic to determine whether the distribution of the observed data is plausible under the hypothesis. This rejection occurs when the calculated test statistic is higher than some pre-specified threshold value.\n",
    "\n",
    "> In the frequentist approach, the _sampling distribution_ is approximated from the mean and standard error.\n",
    "\n",
    "### The Bayesian strategy\n",
    "The Bayesian approach for evaluating differences between groups is \"estimation\" rather than \"testing\". Instead of asking \"are the two groups different?\", we instead ask \"_how_ different are the two groups?\" This is the subtle difference in estimation as opposed to testing. We are measuring the extent of the difference between the groups, whether it be zero or any other value.\n",
    "\n",
    "For a more detailed treatment feel free to read the documentation linked above.\n",
    "\n",
    "> In the Bayesian approach, the _sampling distribution_ is approximated through repeated sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='load'></a>\n",
    "### Get the APM for 19 and 26 year olds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate the mean for the two groups and the empirical difference between means.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='freq-ttest'></a>\n",
    "### Perform a Frequentist t-test of the mean APM difference between groups.\n",
    "\n",
    "What is the null hypothesis? What is the alternative hypothesis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:\n",
    "tt = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Plot the t-statistic for the test on the t-distribution.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:\n",
    "zdist = stats.norm(0, 1)\n",
    "xvals = np.linspace(-4, 4, 200)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7,5))\n",
    "ax.plot(xvals, zdist.pdf(xvals), lw=3)\n",
    "ax.axvline(tt.statistic, color='black', ls='dashed', lw=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the `pymc3` docs (http://docs.pymc.io/notebooks/BEST.html):\n",
    "\n",
    "> Unfortunately, it is not easy to conduct hypothesis tests correctly, and their results are very easy to misinterpret. Setting up a statistical test involves several subjective choices (e.g. statistical test to use, null hypothesis to test, significance level) by the user that are rarely justified based on the problem or decision at hand, but rather, are usually based on traditional choices that are entirely arbitrary (Johnson 1999). The evidence that it provides to the user is indirect, incomplete, and typically overstates the evidence against the null hypothesis (Goodman 1999)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='priors'></a>\n",
    "### Set up the bayesian model with priors on mean APMs\n",
    "\n",
    "Next we'll go through the steps of the Bayesian estimation of the difference between means using `pymc3`.\n",
    "\n",
    "In what follows, we will build _two_ Bayesian models of the APM: one for 19 and one for 26 year olds.  We will estimate the mean and standard deviation of each group using Bayes' Theorem.  At the end, we can compare the _posterior_ estimates of these means to determine if there is a significant difference or not.  We can determine statistical significance in this case, by assessing whether the _probability distributions **of the means** overlap, or not._\n",
    "\n",
    "First we find the mean and standard deviation of APM regardless of age group. We can going to use these values to inform our prior belief about APM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='construct-priors'></a>\n",
    "### Construct the prior distributions on the means\n",
    "\n",
    "> **Note**: `pymc3` sets up models using the Python `with ... :` syntax.\n",
    "\n",
    "The first thing we are going to set up is our prior belief about the mean APM for our 19 year olds and 26 year olds. _These are not fixed values,_ but rather normal distributions covering a range of possible values for the mean APM for each group with varying likelihoods.\n",
    "\n",
    "We are going to set up the normal distributions to both take the overall mean and standard deviation of the actions per minute for all players. In other words, our prior belief for each group's mean APM is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='std-priors'></a>\n",
    "### Priors on standard deviations\n",
    "\n",
    "What we set up before are the prior distributions for the _means_ of APM for the two age groups, but we can also set up priors on the standard deviations for APM for each group.\n",
    "\n",
    "Our standard deviation priors can be \"uninformative\": uniformly distributed from close to 0 up to 100. We are saying that we believe all standard deviations in those ranges to be equally likely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='apm-dists'></a>\n",
    "### Set up the APM distributions for the two groups\n",
    "\n",
    "Now that we have our prior beliefs about the mean and standard deviation of APM for each age group, we can construct what will be the posterior distributions for the APMs after \"observing\" the data.\n",
    "\n",
    "For each group we set up a `pm.Normal` distribution to represent the likelihood of the observed APM data. The mean `mu=` will be our prior belief distribution of the mean for that group. Likewise the `sd=` will be the prior distribution for standard deviation of APM for that group. \n",
    "\n",
    "Lastly, we provide the vectors of data for the `observed=` parameter. This is the actual, measured APM data. When we \"fit\" this model (using MCMC or another sampling strategy under the hood), the posterior distributions will be updated according to our prior beliefs and our data – just like in Bayes formula!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='metrics'></a>\n",
    "### Tracking additional metrics\n",
    "\n",
    "The last thing we'll do before fitting the model is define some distributions that will make it easier for us to evaluate the difference between mean APMs of the two groups. \n",
    "\n",
    "`pm.Deterministic` distributions are defined from other distributions in the model. For example, we can set up `diff_of_means` to be defined by `group19_mean - group26_mean`, making this a distribution of the differences between means between groups as the posteriors are iteratively fit/estimated.\n",
    "\n",
    "We can also set up a distribution for the efect size by taking the difference between means and dividing by the pooled standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fit'></a>\n",
    "### Fitting the `pymc3` model\n",
    "\n",
    "When we call `trace = pm.sample(...)` we are starting a sampling process to estimate the posterior distribution. `pymc3` has the option to do MCMC, but defaults to the NUTS sampler. NUTS stands for No U-Turn Sampler and is a state-of-the-art posterior estimation algorithm.\n",
    "\n",
    "The \"trace\" is a collection of all the values on the posterior distribution \"visited\" during the sampling procedure. The values in the trace define the posterior distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='plotting'></a>\n",
    "### Plotting the posteriors and metric distributions\n",
    "\n",
    "`pymc3` comes with convenient methods for plotting posteriors. Below we plot our posterior means and standard deviations. The relevant statistics about the distributions are automatically added to the plots.\n",
    "\n",
    "The HPD is the Highest Posterior Density interval. This gives us a Bayesian \"credible interval\" which is the corollary to the Frequentist confidence interval. The 95% HPD says that the 95% highest density points on the distribution fall within that range.\n",
    "\n",
    "**Take a look at the first element of the `trace`:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use the `pm.plot_posterior` function to look at the posterior distributions for the group means and standard deviations.**\n",
    "\n",
    "> **Note:** It is common to slice off the initial portion of the trace. This is known as the \"burn-in\". The sampling procedure often starts far away from the correct estimates, and so slicing off the beginning can get rid of the cruft. It is also common to not take every sample, but skip every two or three. I am not doing that here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the posteriors of our metric distributions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The `pm.summary` function can also display a text representation of this information:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
