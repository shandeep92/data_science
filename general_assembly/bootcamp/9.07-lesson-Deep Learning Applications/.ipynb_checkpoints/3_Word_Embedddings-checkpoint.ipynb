{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 79
    },
    "colab_type": "code",
    "id": "X0S4ukr6UJHI",
    "outputId": "b099df7d-0df3-4439-f6d4-950b9ef04ad6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SeLSphegUOK-"
   },
   "outputs": [],
   "source": [
    "# define documents\n",
    "docs = ['Well done!',\n",
    "\t\t'Good work',\n",
    "\t\t'Great effort',\n",
    "\t\t'nice work',\n",
    "\t\t'Excellent!',\n",
    "\t\t'Weak',\n",
    "\t\t'Poor effort!',\n",
    "\t\t'not good',\n",
    "\t\t'poor work',\n",
    "\t\t'Could have done better.']\n",
    "# define class labels\n",
    "labels = array([1,1,1,1,1,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jvpNnnD_VGDm"
   },
   "source": [
    "**Method 1 to Encode**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "coXZZlqrUUBU",
    "outputId": "9b399b31-d65d-48ea-cb2c-49eac7caeaa1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16, 38], [44, 34], [22, 49], [8, 34], [42], [14], [14, 49], [24, 44], [14, 34], [14, 30, 38, 12]]\n"
     ]
    }
   ],
   "source": [
    "# integer encode the documents\n",
    "vocab_size = 50\n",
    "encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
    "print(encoded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rgriLSwvVR4k"
   },
   "source": [
    "**Method 2 to Encode**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rM46RA4lUYU7",
    "outputId": "d74c5929-4b4a-40b5-e31e-948382e37005"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 2], [3, 1], [7, 4], [8, 1], [9], [10], [5, 4], [11, 3], [5, 1], [12, 13, 2, 14]]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "# integer encode text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(docs)\n",
    "encoded = tokenizer.texts_to_sequences(docs)\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mrx6ZDD2VW3q",
    "outputId": "b300353a-85de-43ac-d712-99da5621aa39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 15\n"
     ]
    }
   ],
   "source": [
    "# determine the vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Vocabulary Size: %d' % vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LeVr0n6HWOnR"
   },
   "source": [
    "**Padding Sequences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "-xpd-UZZVm34",
    "outputId": "9f6578e8-e528-42a6-80fc-384f08875eda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6  2  0  0]\n",
      " [ 3  1  0  0]\n",
      " [ 7  4  0  0]\n",
      " [ 8  1  0  0]\n",
      " [ 9  0  0  0]\n",
      " [10  0  0  0]\n",
      " [ 5  4  0  0]\n",
      " [11  3  0  0]\n",
      " [ 5  1  0  0]\n",
      " [12 13  2 14]]\n"
     ]
    }
   ],
   "source": [
    "# pad documents to a max length of 4 words\n",
    "max_length = 4\n",
    "padded_docs = pad_sequences(encoded, maxlen=max_length, padding='post')\n",
    "print(padded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NDYzSKo6WL5D"
   },
   "outputs": [],
   "source": [
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 8, input_length=max_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "yS9qyR1EWsGF",
    "outputId": "c7726059-9157-4853-bdca-b97aef26c75e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 4, 8)              120       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 153\n",
      "Trainable params: 153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    " #compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# summarize the model\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "colab_type": "code",
    "id": "ctdzlxDEW08a",
    "outputId": "6e34ef2b-44ba-49d6-a42c-ceedb3bcb5e1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gateam/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 0.6923 - accuracy: 0.6000\n",
      "Epoch 2/25\n",
      "10/10 [==============================] - 0s 340us/step - loss: 0.6909 - accuracy: 0.6000\n",
      "Epoch 3/25\n",
      "10/10 [==============================] - 0s 231us/step - loss: 0.6893 - accuracy: 0.6000\n",
      "Epoch 4/25\n",
      "10/10 [==============================] - 0s 758us/step - loss: 0.6876 - accuracy: 0.6000\n",
      "Epoch 5/25\n",
      "10/10 [==============================] - 0s 400us/step - loss: 0.6857 - accuracy: 0.6000\n",
      "Epoch 6/25\n",
      "10/10 [==============================] - 0s 310us/step - loss: 0.6839 - accuracy: 0.6000\n",
      "Epoch 7/25\n",
      "10/10 [==============================] - 0s 484us/step - loss: 0.6821 - accuracy: 0.7000\n",
      "Epoch 8/25\n",
      "10/10 [==============================] - 0s 264us/step - loss: 0.6802 - accuracy: 0.7000\n",
      "Epoch 9/25\n",
      "10/10 [==============================] - 0s 472us/step - loss: 0.6784 - accuracy: 0.7000\n",
      "Epoch 10/25\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6766 - accuracy: 0.8000\n",
      "Epoch 11/25\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6748 - accuracy: 0.8000\n",
      "Epoch 12/25\n",
      "10/10 [==============================] - 0s 203us/step - loss: 0.6730 - accuracy: 0.8000\n",
      "Epoch 13/25\n",
      "10/10 [==============================] - 0s 298us/step - loss: 0.6712 - accuracy: 0.8000\n",
      "Epoch 14/25\n",
      "10/10 [==============================] - 0s 323us/step - loss: 0.6693 - accuracy: 0.8000\n",
      "Epoch 15/25\n",
      "10/10 [==============================] - 0s 815us/step - loss: 0.6675 - accuracy: 0.8000\n",
      "Epoch 16/25\n",
      "10/10 [==============================] - 0s 395us/step - loss: 0.6657 - accuracy: 0.8000\n",
      "Epoch 17/25\n",
      "10/10 [==============================] - 0s 467us/step - loss: 0.6639 - accuracy: 0.9000\n",
      "Epoch 18/25\n",
      "10/10 [==============================] - 0s 539us/step - loss: 0.6620 - accuracy: 0.9000\n",
      "Epoch 19/25\n",
      "10/10 [==============================] - 0s 428us/step - loss: 0.6602 - accuracy: 0.9000\n",
      "Epoch 20/25\n",
      "10/10 [==============================] - 0s 407us/step - loss: 0.6584 - accuracy: 1.0000\n",
      "Epoch 21/25\n",
      "10/10 [==============================] - 0s 676us/step - loss: 0.6565 - accuracy: 1.0000\n",
      "Epoch 22/25\n",
      "10/10 [==============================] - 0s 283us/step - loss: 0.6547 - accuracy: 1.0000\n",
      "Epoch 23/25\n",
      "10/10 [==============================] - 0s 521us/step - loss: 0.6528 - accuracy: 1.0000\n",
      "Epoch 24/25\n",
      "10/10 [==============================] - 0s 320us/step - loss: 0.6510 - accuracy: 1.0000\n",
      "Epoch 25/25\n",
      "10/10 [==============================] - 0s 356us/step - loss: 0.6491 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x63109c3c8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(padded_docs, labels, epochs=25, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ysdX_bZbW3Ii",
    "outputId": "b911472d-24d1-473d-d5d3-0a58a1157cc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.000000\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Q7T_t4W2XqH3",
    "outputId": "2ef14fae-d6b3-467d-da93-d07f5e879fa3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 4)"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_docs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Yvvx2U4iXUtu",
    "outputId": "8a848fd4-ae79-4ca5-e204-b4e611563b5b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_docs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qyVBONulYiIq",
    "outputId": "41998b55-35da-458b-c03d-00b4fb4b19cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4, 1)"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_docs[1].reshape(1,4,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "emJ-RncUW_Ye",
    "outputId": "963fa223-b539-4263-9248-684e6d7f8043"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0]], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "model.predict_classes(padded_docs[5].reshape(1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "K6So9eEBXR2-",
    "outputId": "3bde6ee7-c032-4be7-c80a-f37cec189505"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gz8EIogoZ2rr"
   },
   "source": [
    "Using a custom word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "R32DEqQzYr_G",
    "outputId": "1adc42eb-9371-441e-9156-2ddc8b6bfeb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: wget: command not found\n",
      "unzip:  cannot find or open glove6b100dtxt.zip, glove6b100dtxt.zip.zip or glove6b100dtxt.zip.ZIP.\n"
     ]
    }
   ],
   "source": [
    "!wget -qq https://www.dropbox.com/s/v14xhvjmfniraf3/glove6b100dtxt.zip\n",
    "!unzip glove6b100dtxt.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FelAjSZFZ9Pe",
    "outputId": "2f5c18d0-d358-45ca-e576-5e722d9a942d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "from numpy import asarray\n",
    "# load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "f = open('glove.6B.100d.txt')\n",
    "for line in f:\n",
    "\tvalues = line.split()\n",
    "\tword = values[0]\n",
    "\tcoefs = asarray(values[1:], dtype='float32')\n",
    "\tembeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "colab_type": "code",
    "id": "PNMRAZxxaLlj",
    "outputId": "976a5d3a-7b1c-492e-a009-0ad31893f21e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.26688  ,  0.39632  ,  0.6169   , -0.77451  , -0.1039   ,\n",
       "        0.26697  ,  0.2788   ,  0.30992  ,  0.0054685, -0.085256 ,\n",
       "        0.73602  , -0.098432 ,  0.5479   , -0.030305 ,  0.33479  ,\n",
       "        0.14094  , -0.0070003,  0.32569  ,  0.22902  ,  0.46557  ,\n",
       "       -0.19531  ,  0.37491  , -0.7139   , -0.51775  ,  0.77039  ,\n",
       "        1.0881   , -0.66011  , -0.16234  ,  0.9119   ,  0.21046  ,\n",
       "        0.047494 ,  1.0019   ,  1.1133   ,  0.70094  , -0.08696  ,\n",
       "        0.47571  ,  0.1636   , -0.44469  ,  0.4469   , -0.93817  ,\n",
       "        0.013101 ,  0.085964 , -0.67456  ,  0.49662  , -0.037827 ,\n",
       "       -0.11038  , -0.28612  ,  0.074606 , -0.31527  , -0.093774 ,\n",
       "       -0.57069  ,  0.66865  ,  0.45307  , -0.34154  , -0.7166   ,\n",
       "       -0.75273  ,  0.075212 ,  0.57903  , -0.1191   , -0.11379  ,\n",
       "       -0.10026  ,  0.71341  , -1.1574   , -0.74026  ,  0.40452  ,\n",
       "        0.18023  ,  0.21449  ,  0.37638  ,  0.11239  , -0.53639  ,\n",
       "       -0.025092 ,  0.31886  , -0.25013  , -0.63283  , -0.011843 ,\n",
       "        1.377    ,  0.86013  ,  0.20476  , -0.36815  , -0.68874  ,\n",
       "        0.53512  , -0.46556  ,  0.27389  ,  0.4118   , -0.854    ,\n",
       "       -0.046288 ,  0.11304  , -0.27326  ,  0.15636  , -0.20334  ,\n",
       "        0.53586  ,  0.59784  ,  0.60469  ,  0.13735  ,  0.42232  ,\n",
       "       -0.61279  , -0.38486  ,  0.35842  , -0.48464  ,  0.30728  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index['hello']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iBr7BuhIalTt"
   },
   "outputs": [],
   "source": [
    "from numpy import zeros\n",
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = zeros((vocab_size, 100))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "\tembedding_vector = embeddings_index.get(word)\n",
    "\tif embedding_vector is not None:\n",
    "\t\tembedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "colab_type": "code",
    "id": "ezS87Pbqa_Fg",
    "outputId": "2ec3f3b4-d446-49c0-b45c-638145ef6119"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 4, 100)            5000      \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 401       \n",
      "=================================================================\n",
      "Total params: 5,401\n",
      "Trainable params: 401\n",
      "Non-trainable params: 5,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=4, trainable=False)\n",
    "model.add(e)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rL2VCyxibcjP",
    "outputId": "72a01baa-909a-4144-e49c-d4f258d283b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.000000\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(padded_docs, labels, epochs=50, verbose=0)\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RiFp0GrVbgLG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Word_Embedddings.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
