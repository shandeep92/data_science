{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "## Generalized Linear Models\n",
    "\n",
    "_Authors: Tim Book, Justin Pounders (ATL), Matt Brems_\n",
    "\n",
    "### Learning Objectives\n",
    "*After this lesson, students will be able to:*\n",
    "\n",
    "1. Describe generalized linear models.\n",
    "2. Fit Poisson and Gamma regression models in `statsmodels`.\n",
    "3. Interpret coefficients from Poisson and Gamma regression models.\n",
    "4. Describe iteratively reweighted least squares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall: The Anatomy of a GLM\n",
    "GLMs are made up of three components:\n",
    "* **Systematic component** (or **linear component**) - The choice of _x_-variables in your model.\n",
    "* **Random component** - Distributional assumption of $y_i$.\n",
    "* **Link function** - The function that connects systematic and random components. Must input the range of possible values of $\\mu_i$ and output $\\mathbb{R}$.\n",
    "\n",
    "While there are many kinds of GLMs out there, today we'll focus on two new commonly used ones:\n",
    "* **Poisson regression**\n",
    "* **Gamma regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `statsmodels` API\n",
    "\n",
    "We will use the `statsmodels` API to explore GLMs in Python.  (`sklearn` does not have a robust implementation for GLMs.)  Documentation and examples for `statsmodels` can be found [here](http://www.statsmodels.org/stable/generated/statsmodels.genmod.generalized_linear_model.GLM.html#statsmodels.genmod.generalized_linear_model.GLM).\n",
    "\n",
    "Fitting GLMs in `statsmodels` will be as easy as using the `sm.GLM()` class and setting the three components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poisson Regression\n",
    "\n",
    "**When do we use it?** When we want to model something on the $\\{0,1,2,\\ldots\\}$ range... like number of cars on through a toll road, number of objects sold or number of awards earned!\n",
    "\n",
    "<img src=\"./images/poisson_model.png\" alt=\"poisson_model\" width=\"400\"/>\n",
    "\n",
    "#### Data\n",
    "We'll rely on UCLA's IDRE module.  This one can be found [here](https://stats.idre.ucla.edu/r/dae/poisson-regression/).\n",
    "\n",
    "#### Data Description\n",
    "_The number of awards earned by students at one high school. Predictors of the number of awards earned include the type of program in which the student was enrolled (e.g., vocational, general or academic) and the score on their final exam in math._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data.\n",
    "award = pd.read_csv(\"https://stats.idre.ucla.edu/stat/data/poisson_sim.csv\")\n",
    "\n",
    "# Check first five rows.\n",
    "award.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a scatterplot of math vs. number of awards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of awards by program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>What might we infer from this plot?</summary>\n",
    "\n",
    "- `prog` is definitely not linearly related to the number of awards one receives.\n",
    "- `prog` looks like a categorical variable.\n",
    "- I am aware of this. I'm going to suspend that knowledge for the sake of example.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set up X.\n",
    "\n",
    "# Set up y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the three components of a poisson regression GLM?\n",
    "# Systematic component - We already picked this\n",
    "# Random component -\n",
    "# Link function -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model.\n",
    "# In statsmodels, y is the first argument.\n",
    "# In statsmodels, X is the second argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary of model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpreting Poisson Coefficients\n",
    "\n",
    "Because of the log link function, we interpret a one-unit increase in $X_i$ as follows:\n",
    "\n",
    "\"As $X_i$ increases by 1, I expect $Y$ to increase by a factor of $e^{\\beta_1}$.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: For a one-unit increase in `math`, I expect to win $e^{0.0702} \\approx 1.07$ times as many awards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<details><summary>How would you interpret `prog_2`?</summary>\n",
    "    If you are in Program 2, I expect to win $e^{1.0839} \\approx 3$ times as many awards as if you were in Program 1.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Gamma Regression\n",
    "\n",
    "**When do we use it?** When we want to model something on the $[0,\\infty)$ range... like time until some event occurs!\n",
    "\n",
    "### The Data\n",
    "The data used from this example come from a 1945 study about and is inspired by [Peter Craigmile's use](http://www.craigmile.com/peter/teaching/7430/notes/7_gamma_influence.pdf) of this example.\n",
    "\n",
    "**Data Description:** _“Hurn, et al. (1945) published data on the clotting time of blood, giving clotting time in seconds for normal plasma diluted to nine different percentage concentrations with prothrombin-free plasma; clotting was induced by two lots of thromboplastin.” [McCullagh and Nelder](http://www.utstat.toronto.edu/~brunner/oldclass/2201s11/readings/glmbook.pdf)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data in.\n",
    "clot = pd.read_csv(\"datasets/clotting.csv\", index_col=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the first five rows.\n",
    "clot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a boxplot of clot_time group by lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot plasma_pct against clot_time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the base 10 log of plasma_pct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot our new variable against clot_time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up X.\n",
    "\n",
    "# Set up y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model.\n",
    "# NOTE: For prediction purposes, the inverse link might actually be best (it's the \"canonical link\")\n",
    "# but the log link allows us to interpret our coefficients.\n",
    "# In statsmodels, y is the first argument.\n",
    "# In statsmodels, X is the second argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary of model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpreting Gamma Coefficients\n",
    "\n",
    "Because of the log link function (again!), we interpret a one-unit increase in $X_i$ as follows:\n",
    "\n",
    "\"As $X_i$ increases by 1, I expect $Y$ to increase by a factor of $e^{\\beta_1}$.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponentiate our coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: For a one-unit increase in `plasma_pct`, I expect the blood will take $e^{-0.0156} \\approx 26\\%$ as much time to clot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Iteratively Reweighted Least Squares\n",
    "\n",
    "When fitting an OLS regression model, we can find our best values for $\\beta$ by solving $\\hat{\\pmb\\beta} = (X^TX)^{-1}X^Ty$.\n",
    "\n",
    "GLMs are typically not \"directly solvable.\" There is [no closed-form solution](http://mathworld.wolfram.com/Closed-FormSolution.html) for generalized linear models!\n",
    "- This includes logistic regression!\n",
    "\n",
    "#### How does the algorithm work?\n",
    "An algorithm called \"iteratively reweighted least squares\" [has been shown](http://www.utstat.toronto.edu/~brunner/oldclass/2201s11/readings/glmbook.pdf) is \"easy\" to implement in a computer.\n",
    "- A solution is initially guessed, then iteratively refined until we converge on an answer.\n",
    "- IRLS is a special cause of a **gradient descent algorithm**. We'll learn about gradient descent tomorrow.\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\\hat{\\pmb\\beta}_{[1]} &=& (X^TW_1X)^{-1}X^TW_1y \\\\\n",
    "\\Rightarrow \\hat{\\pmb\\beta}_{[2]} &=& (X^TW_2X)^{-1}X^TW_2y \\\\\n",
    "\\Rightarrow \\hat{\\pmb\\beta}_{[3]} &=& (X^TW_3X)^{-1}X^TW_3y \\\\\n",
    "\\Rightarrow \\hat{\\pmb\\beta}_{[4]} &=& (X^TW_4X)^{-1}X^TW_4y \\\\\n",
    "\\Rightarrow \\hat{\\pmb\\beta}_{[5]} &=& (X^TW_5X)^{-1}X^TW_5y \\\\\n",
    "&\\vdots& \\\\\n",
    "\\Rightarrow \\hat{\\pmb\\beta}_{[99]} &=& (X^TW_{99}X)^{-1}X^TW_{99}y \\\\\n",
    "\\Rightarrow \\hat{\\pmb\\beta}_{[100]} &=& (X^TW_{100}X)^{-1}X^TW_{100}y \\\\\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "- At each step (\"iteration\"), these weights will change. (\"reweighted\")\n",
    "\n",
    "The default maximum number of iterations for GLMs in `statsmodels` is 100. \n",
    "- If `No. Iterations` is less than 100, that means the algorithm probably converged.\n",
    "- If `No. Iterations` is 100, that means the algorithm probably didn't converge and that the $\\mathbf{\\hat{\\beta}}$ are still changing. Therefore, **your output is unreliable - DO NOT USE IT**. It could also give some information on the \"flatness\" of your error function. Even more than 20 iterations is sketchy.\n",
    "\n",
    "There are potential pitfalls to this algorithm (some of which we'll cover later). However, what you should know:\n",
    "- If you get a `ConvergenceWarning` or any indication that your number of iterations is large, that means that your model did not fit properly and that you should not rely on the results!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Did our results converge?\n",
    "results.converged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Today, we:\n",
    "* Learned how to generalize two models we already knew (linear and logistic regression) into a borader category of models (GLMs)\n",
    "* Refamiliarized ourselves with the `statsmodels` API\n",
    "* Learned the components of GLMs, and how to customize them with `statsmodels`:\n",
    "    - Systematic/linear component, ie, our choice of x-variables\n",
    "    - Link function - a function we choose to \"bend\" our response to our y-variable\n",
    "    - Random component - The distribution that represents the data-generation process for our y-variable\n",
    "* Two new linear models:\n",
    "    - **Poisson regression** - For when your y-variable is Poisson distributed. Most commonly used for _count data_.\n",
    "        - e.g. Predicting how many children a couple will have based on age and income\n",
    "    - **Gamma regression** - For when your y-variable is Gamma distributed. Most commonly used for _waiting-time data_.\n",
    "        - e.g. Predicting how long your phone's battery will last based on screentime use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/glm-sheet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Picking other GLMs (BONUS)\n",
    "\n",
    "Chosing the right kind of generalized linear model (GLM) from all possibilities really boils down to picking the \"error.\"\n",
    "\n",
    "The \"error\" model is really telling you how you expect observations to be distributed.  It is a probability distribution.\n",
    "\n",
    "> 1. In traditional linear regression, the error term is a normal distribution.  This means that you expect actual observations to be normally distributed around your line.\n",
    "\n",
    "> 2. In logistic regression, the error term is a Bernoulli distribution.  This means that you expect actual observations to be above (1) or below (0) the logit curve with a certain probability.\n",
    "\n",
    "Choosing the distribution function often points to a link function you should use: [here is a table](https://en.wikipedia.org/wiki/Generalized_linear_model#Link_function).\n",
    "\n",
    "Examples:\n",
    "\n",
    "1. If $Y$ is a non-negative integer:\n",
    "   - Poisson regression if mean $\\approx$ variance\n",
    "   - Negative Binomial regression if variance $\\gg$ mean (overdisperse)\n",
    "   - For example,\n",
    "     - Units sold\n",
    "     - Customers through the door\n",
    "     - Patients to the ER\n",
    "     - Number of cars racing the red light\n",
    "2. If $Y$ values represent categories\n",
    "   - Multinomial logistic regression (unordered categories)\n",
    "   - Ordinal logstic regression (ordered categories)\n",
    "   - For example,\n",
    "     - Does a population tend to buy groceries at Whole Foods, Publix or Kroger?\n",
    "     - Will millenials vote democrat, republican or independent?\n",
    "     - Predicting the Amazon star rating of books.\n",
    "3. If $Y$ values are continuous, non-negative\n",
    "   - Gamma regression\n",
    "   - For example,\n",
    "     - How long before my Uber/Lyft gets here?\n",
    "     - Home prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Deviance (BONUS)\n",
    "\n",
    "We've spoken briefly about deviance before as a generalization of the sums of squares of error for generalized linear models.\n",
    "\n",
    "Suppose we have two models:\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "Y_{full} &=& \\beta_0 + \\beta_1X_1 + \\cdots + \\beta_kX_k + \\cdots + \\beta_pX_p + \\varepsilon \\\\\n",
    "Y_{reduced} &=& \\beta_0 + \\beta_1X_1 + \\cdots + \\beta_kX_k + \\varepsilon\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "We say that $Y_{reduced}$ is nested in $Y_{full}$, because the reduced model could \"fit inside\" the full. (You can learn more about nested linear regression models [here](http://people.reed.edu/~jones/Courses/P24.pdf), although the ideas approximately hold for generalized linear models as well.)\n",
    "\n",
    "When we have one model nested inside the other, there is a statistical test to see if adding new variables are worth it. (Think about it like looking at the difference in mean squared error or $R^2$ by adding a variable, but getting a $p$-value quantifying whether or not it's worth it!)\n",
    "\n",
    "We calculate the **deviance** of the reduced model and subtract the **deviance** of the full model from it. This difference in deviance follows a [chi-squared distribution](https://en.wikipedia.org/wiki/Chi-squared_distribution) with $p-k$ degrees of freedom. (Note that $p-k$ indicates how many variables we took out of our full model to get to the reduced model!)\n",
    "\n",
    "**This comparison only works with nested models! Do not use if your models are not nested!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model differences\n",
    "from scipy.stats import chi2\n",
    "\n",
    "grad = pd.read_csv(\"https://stats.idre.ucla.edu/stat/data/binary.csv\")\n",
    "\n",
    "# First, build our top model\n",
    "indep_vars = ['gre', 'gpa', 'rank']\n",
    "X = sm.add_constant(grad[indep_vars])\n",
    "y = grad.admit\n",
    "\n",
    "glm_logit = sm.GLM(y, \n",
    "                   X,\n",
    "                   sm.families.Binomial(sm.families.links.logit))\n",
    "results_logit = glm_logit.fit()\n",
    "\n",
    "\n",
    "# Next, let's see if we can safely reduce our model\n",
    "reduced_vars = ['gre', 'gpa']\n",
    "X_reduced = sm.add_constant(grad[reduced_vars])\n",
    "\n",
    "results_reduced = sm.GLM(y,\n",
    "                 X_reduced,\n",
    "                 sm.families.Binomial(sm.families.links.logit)).fit()\n",
    "results_reduced.summary()\n",
    "\n",
    "\n",
    "# Calculate the difference in deviance\n",
    "D = results_reduced.deviance - results_logit.deviance\n",
    "print('Difference in Deviance: ', D)\n",
    "\n",
    "# Check to see if this difference is significant\n",
    "pval = 1 - chi2.cdf(D, df = 1)\n",
    "print('p-value of test of difference: ', pval) # What can we conclude here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H_0:$ reduced model is better\n",
    "\n",
    "$H_A:$ reduced model is not better\n",
    "\n",
    "Because $p < \\alpha$, we reject $H_0$ and conclude that the reduced model is not better."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
