{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Hyperparameters, GridSearch, and Pipelines\n",
    "\n",
    "_Authors: Kiefer Katovich (SF), David Yerrington (SF), Matt Brems_\n",
    "\n",
    "---\n",
    "\n",
    "![](https://snag.gy/aYcCt2.jpg)\n",
    "\n",
    "### Learning Objectives\n",
    "- Describe what the terms hyperparameters, GridSearch, and pipeline mean.\n",
    "- Apply `sklearn`'s `GridSearchCV` object.\n",
    "- Use attributes of the GridSearch object.\n",
    "- Describe the pitfalls of searching large hyperparameter spaces.\n",
    "- Build pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>region</th>\n",
       "      <th>lifeMale</th>\n",
       "      <th>lifeFemale</th>\n",
       "      <th>infantMortality</th>\n",
       "      <th>GDPperCapita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Asia</td>\n",
       "      <td>45.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>154</td>\n",
       "      <td>2848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>Europe</td>\n",
       "      <td>68.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>32</td>\n",
       "      <td>863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>Africa</td>\n",
       "      <td>67.5</td>\n",
       "      <td>70.3</td>\n",
       "      <td>44</td>\n",
       "      <td>1531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Angola</td>\n",
       "      <td>Africa</td>\n",
       "      <td>44.9</td>\n",
       "      <td>48.1</td>\n",
       "      <td>124</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>America</td>\n",
       "      <td>69.6</td>\n",
       "      <td>76.8</td>\n",
       "      <td>22</td>\n",
       "      <td>8055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country   region  lifeMale  lifeFemale  infantMortality  GDPperCapita\n",
       "0  Afghanistan     Asia      45.0        46.0              154          2848\n",
       "1      Albania   Europe      68.0        74.0               32           863\n",
       "2      Algeria   Africa      67.5        70.3               44          1531\n",
       "3       Angola   Africa      44.9        48.1              124           355\n",
       "4    Argentina  America      69.6        76.8               22          8055"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in data.\n",
    "data = pd.read_csv('../data/UNdata.csv')\n",
    "\n",
    "# Examine first five rows.\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## United Nations Data\n",
    "\n",
    "- `country`: the name of the nation\n",
    "- `region`: the region of the world (Africa, America, Asia, Europe, Oceania)\n",
    "- `lifeMale`: the life expectancy of males\n",
    "- `lifeFemale`: the life expectancy of females\n",
    "- `infantMortality`: the infant mortality rate (generally reported per 1,000 live births)\n",
    "- `GDPperCapita`: the Gross Domestic Product per person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country            0\n",
       "region             0\n",
       "lifeMale           0\n",
       "lifeFemale         0\n",
       "infantMortality    0\n",
       "GDPperCapita       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values.\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set country to be the index.\n",
    "data.set_index('country', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>lifeMale</th>\n",
       "      <th>lifeFemale</th>\n",
       "      <th>infantMortality</th>\n",
       "      <th>GDPperCapita</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Afghanistan</th>\n",
       "      <td>Asia</td>\n",
       "      <td>45.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>154</td>\n",
       "      <td>2848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albania</th>\n",
       "      <td>Europe</td>\n",
       "      <td>68.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>32</td>\n",
       "      <td>863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algeria</th>\n",
       "      <td>Africa</td>\n",
       "      <td>67.5</td>\n",
       "      <td>70.3</td>\n",
       "      <td>44</td>\n",
       "      <td>1531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Angola</th>\n",
       "      <td>Africa</td>\n",
       "      <td>44.9</td>\n",
       "      <td>48.1</td>\n",
       "      <td>124</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Argentina</th>\n",
       "      <td>America</td>\n",
       "      <td>69.6</td>\n",
       "      <td>76.8</td>\n",
       "      <td>22</td>\n",
       "      <td>8055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              region  lifeMale  lifeFemale  infantMortality  GDPperCapita\n",
       "country                                                                  \n",
       "Afghanistan     Asia      45.0        46.0              154          2848\n",
       "Albania       Europe      68.0        74.0               32           863\n",
       "Algeria       Africa      67.5        70.3               44          1531\n",
       "Angola        Africa      44.9        48.1              124           355\n",
       "Argentina    America      69.6        76.8               22          8055"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy region.\n",
    "data = pd.get_dummies(data, columns=['region'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>What is our reference category for this dummy variable?</summary>\n",
    "\n",
    "- Africa!\n",
    "- There is no dummy variable for Africa in our data, meaning that all dummy variables would be interpreted **relative to Africa**.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create $Y$ variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column with 1 if the female life expectancy is greater\n",
    "# than the male life expectancy.\n",
    "data['females_are_strong_as_hell'] = (data['lifeFemale'] > data['lifeMale']).astype(int)\n",
    "\n",
    "# The column name is a reference to the \n",
    "# Netflix series \"The Unbreakable Kimmy Schmidt.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.989362\n",
       "0    0.010638\n",
       "Name: females_are_strong_as_hell, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What should we check next?\n",
    "data['females_are_strong_as_hell'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Do you have any concerns about the above?</summary>\n",
    "    \n",
    "- Our classes are severely unbalanced.\n",
    "- We should check out our tools for handling unbalanced classes. (e.g. moving our classification threshold, implement stratified $k$-fold cross-validation)\n",
    "- Given the relatively low sample size and the small number of the observations in the minority category here, it is unlikely that our model would be able to predict that a nation has a higher male life expectancy.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.569149\n",
       "1    0.430851\n",
       "Name: females_are_strong_as_hell, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a column with 1 if the female life expectancy is 5\n",
    "# or more years longer than the male life expectancy.\n",
    "data['females_are_strong_as_hell'] = (data['lifeFemale'] >= (data['lifeMale'] + 5)).astype(int)\n",
    "\n",
    "# Check the thing we need to check!\n",
    "data['females_are_strong_as_hell'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We are interested in predicting whether or not the female life expectancy of a nation is at least five years greater than the male life expectancy.** This is a classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up X and y.\n",
    "X = data.drop(['females_are_strong_as_hell', 'lifeMale', 'lifeFemale'], axis = 'columns')\n",
    "y = data['females_are_strong_as_hell']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our data into training and testing sets.\n",
    "# I've picked to have a test size of 33% because I want to \n",
    "# make sure that I have enough data in the test set to\n",
    "# meaningfully evaluate my model.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size = 0.33,\n",
    "                                                    random_state = 42,\n",
    "                                                    stratify = y) # Note the stratify argument here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.568\n",
      "1    0.432\n",
      "Name: females_are_strong_as_hell, dtype: float64\n",
      "0    0.571429\n",
      "1    0.428571\n",
      "Name: females_are_strong_as_hell, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# What did stratify = y do?\n",
    "\n",
    "print(y_train.value_counts(normalize=True))\n",
    "\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Before we fit a k-Nearest Neighbors model, what do we need to do? Why?</summary>\n",
    "    \n",
    "- Standardize our data!\n",
    "- If we *don't* standardize our data, then features that have larger spreads (e.g. higher ranges or higher standard deviations) will have a disproportionate influence on our model.\n",
    "- If all of your variables are already on the same scale, then scaling is not necessary.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Instantiate.\n",
    "ss = StandardScaler()\n",
    "\n",
    "# Fit and transform.\n",
    "X_train = ss.fit_transform(X_train)\n",
    "\n",
    "# Transform.\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the Default KNN\n",
    "\n",
    "Below we fit a default `KNeighborsClassifier` to predict `y`. ([Here is the documentation.](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>What is the default number of neighbors used in kNN?</summary>\n",
    "    \n",
    "- 5.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate.\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Fit.\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7619047619047619"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate.\n",
    "knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>What score is this?</summary>\n",
    "\n",
    "- Accuracy.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.571429\n",
       "1    0.428571\n",
       "Name: females_are_strong_as_hell, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate against the baseline.\n",
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Is selecting k = 5 a good choice? Is it the best choice?</summary>\n",
    "\n",
    "- We don't know!\n",
    "- $k$ is a hyperparameter.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are \"hyperparameters?\"\n",
    "\n",
    "Models often have built-in quantities that we can use to fine-tune our results. \n",
    "- What value of $k$ do we select?\n",
    "- What distance metric do we select?\n",
    "- Do we use LASSO or Ridge regularization?\n",
    "- What value of $\\alpha$ or $C$ do we use?\n",
    "\n",
    "These are quantities our model **cannot** learn... **we must decide on these ourselves**!\n",
    "\n",
    "> These are different from statistical parameters, which are quantities a model _can_ learn.\n",
    "\n",
    "However, different values for hyperparameters can result in substantially different models. \n",
    "- Let's [visualize fits for different values of $k$](http://scott.fortmann-roe.com/docs/BiasVariance.html) in $k$-nearest neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>We want to find the optimal values for our hyperparameters. How do you think we might do this?</summary>\n",
    "\n",
    "- Try many different values of hyperparameters and see which ones perform the best on our data.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching for the Best Hyperparameters\n",
    "\n",
    "Our default KNN performs quite poorly on the test data. But what if we changed the number of neighbors? The weighting? The distance metric?\n",
    "\n",
    "These are all hyperparameters of KNN. How would we do this manually? We would need to evaluate on the training data the set of hyperparameters that perform best, and then use this set of hyperparameters to fit the final model and score on the testing set.\n",
    "\n",
    "### Search code for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a random seed.\n",
    "np.random.seed(42)\n",
    "\n",
    "# Let's try 2-NN, 3-NN.\n",
    "neighbors_to_test = [2, 3]\n",
    "\n",
    "# Let's try uniform and distance weightings.\n",
    "weightings_to_test = ['uniform', 'distance']\n",
    "\n",
    "# Let's try Manhattan and Euclidean distances.\n",
    "distance_metrics_to_test = [1, 2] # Remember that p = 1 is Manhattan, p = 2 is Euclidean\n",
    "\n",
    "# Instantiate a dictionary to hold our accuracy scores.\n",
    "accuracies = {}\n",
    "\n",
    "# Loop through number of neighbors.\n",
    "for k in neighbors_to_test:\n",
    "    \n",
    "    # Loop through the weightings.\n",
    "    for w in weightings_to_test:\n",
    "        \n",
    "        # Loop through our distance metrics.\n",
    "        for d in distance_metrics_to_test:\n",
    "            \n",
    "            # Fit a KNN model with that set of hyperparameters.\n",
    "            knn = KNeighborsClassifier(n_neighbors=k, weights=w, p=d)\n",
    "            \n",
    "            # Generate a set of accuracy scores based on 5-fold cross-validation.\n",
    "            cv_accuracies = cross_val_score(knn, X_train, y_train, cv=5)\n",
    "            \n",
    "            # Average the five accuracy scores and store them in the dictionary.\n",
    "            accuracies[(k, w, d)] = np.mean(cv_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code above, we would find the key in the dictionary (a set of hyperparameters) that has the largest value (mean cross-validated accuracy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Based on the above dictionary, which model should I fit?</summary>\n",
    "    \n",
    "- the 2-NN model with distance weighting and the Euclidean distance.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(2, 'uniform', 1): 0.752,\n",
       " (2, 'uniform', 2): 0.728,\n",
       " (2, 'distance', 1): 0.776,\n",
       " (2, 'distance', 2): 0.784,\n",
       " (3, 'uniform', 1): 0.7520000000000001,\n",
       " (3, 'uniform', 2): 0.7360000000000001,\n",
       " (3, 'distance', 1): 0.768,\n",
       " (3, 'distance', 2): 0.7520000000000001}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One method of searching for the optimal set of hyperparameters is called GridSearching.**\n",
    "\n",
    "GridSearching gets its name from the fact that we are searching over a \"grid\" of hyperparameters. For example, imagine the `n_neighbors` hyperparameters as the columns and `distances` as the rows. This makes a grid. We check the accuracy for all combinations of hyperparameters on the grid.\n",
    "\n",
    "![](./images/grid.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `GridSearchCV`\n",
    "\n",
    "This would be an annoying process to have to do manually. Luckily `sklearn` comes in handy:\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "```\n",
    "\n",
    "The `GridSearchCV` has a handful of important arguments:\n",
    "\n",
    "| Argument | Description |\n",
    "| --- | ---|\n",
    "| **`estimator`** | The sklearn instance of the model to fit on |\n",
    "| **`param_grid`** | A dictionary where keys are hyperparameters for the model and values are lists of values to test |\n",
    "| **`cv`** | The number of internal cross-validation folds to run for each set of hyperparameters |\n",
    "| **`n_jobs`** | How many cores to use on your computer to run the folds (-1 means use all cores) |\n",
    "| **`verbose`** | How much output to display (0 is none, 1 is limited, 2 is printouts for every internal fit) |\n",
    "\n",
    "\n",
    "Below is an example for how one might set up the GridSearch for our KNN:\n",
    "\n",
    "```python\n",
    "knn_parameters = {\n",
    "    'n_neighbors':[2,3],\n",
    "    'weights':['uniform','distance'],\n",
    "    'p':[1,2]\n",
    "}\n",
    "\n",
    "knn_gridsearcher = GridSearchCV(KNeighborsClassifier(), knn_parameters, verbose=1)\n",
    "knn_gridsearcher.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "**Try out the `sklearn` GridSearch below on the training data.** [You can find the GridSearchCV documentation here.](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary of hyperparameters.\n",
    "# The keys MUST match the names of the arguments!\n",
    "knn_params = {\n",
    "    'n_neighbors': range(1, 51, 10),\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate our GridSearchCV object.\n",
    "knn_gridsearch = GridSearchCV(KNeighborsClassifier(), # What is the model we want to fit?\n",
    "                              knn_params, # What is the dictionary of hyperparameters?\n",
    "                              cv=5, # What number of folds in CV will we use?\n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "# Fit the GridSearchCV object to the data\n",
    "knn_gridsearch.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining the Results of the GridSearch\n",
    "\n",
    "Once the GridSearch has fit (this can take awhile!) we can pull out a variety of information and useful objects from the GridSearch object, stored as attributes:\n",
    "\n",
    "| Property | Description |\n",
    "| --- | ---|\n",
    "| **`results.param_grid`** | Displays hyperparameters searched over. |\n",
    "| **`results.best_score_`** | Best mean cross-validated score achieved. |\n",
    "| **`results.best_estimator_`** | Reference to model with best score.  Is usable / callable. |\n",
    "| **`results.best_params_`** | The hyperparameters that have been found to perform with the best score. |\n",
    "| **`results.grid_scores_`** | Display score attributes with corresponding hyperparameters. | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.784"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out the best score found in the search.\n",
    "\n",
    "knn_gridsearch.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric': 'euclidean', 'n_neighbors': 1}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out the set of hyperparameters that achieved the best score.\n",
    "knn_gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can store the best fit model (`best_estimator_`) to a variable, then score it on the test data!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7619047619047619"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store the best fit model as best_knn.\n",
    "best_knn = knn_gridsearch.best_estimator_\n",
    "\n",
    "# Evaluate the best fit model on the test data.\n",
    "best_knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's see everything!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_metric</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000935</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.002669</td>\n",
       "      <td>0.001744</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>1</td>\n",
       "      <td>{'metric': 'euclidean', 'n_neighbors': 1}</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.086163</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000753</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.001832</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>11</td>\n",
       "      <td>{'metric': 'euclidean', 'n_neighbors': 11}</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000588</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.001631</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>21</td>\n",
       "      <td>{'metric': 'euclidean', 'n_neighbors': 21}</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.054259</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>31</td>\n",
       "      <td>{'metric': 'euclidean', 'n_neighbors': 31}</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.074189</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000660</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.001644</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>41</td>\n",
       "      <td>{'metric': 'euclidean', 'n_neighbors': 41}</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.059867</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_metric  \\\n",
       "0       0.000935      0.000304         0.002669        0.001744    euclidean   \n",
       "1       0.000753      0.000108         0.001832        0.000254    euclidean   \n",
       "2       0.000588      0.000025         0.001631        0.000182    euclidean   \n",
       "3       0.000756      0.000274         0.002151        0.000438    euclidean   \n",
       "4       0.000660      0.000174         0.001644        0.000058    euclidean   \n",
       "\n",
       "  param_n_neighbors                                      params  \\\n",
       "0                 1   {'metric': 'euclidean', 'n_neighbors': 1}   \n",
       "1                11  {'metric': 'euclidean', 'n_neighbors': 11}   \n",
       "2                21  {'metric': 'euclidean', 'n_neighbors': 21}   \n",
       "3                31  {'metric': 'euclidean', 'n_neighbors': 31}   \n",
       "4                41  {'metric': 'euclidean', 'n_neighbors': 41}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0               0.76               0.84               0.92               0.72   \n",
       "1               0.84               0.76               0.68               0.68   \n",
       "2               0.84               0.84               0.76               0.72   \n",
       "3               0.76               0.76               0.56               0.72   \n",
       "4               0.68               0.76               0.60               0.60   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0               0.68            0.784        0.086163                1  \n",
       "1               0.68            0.728        0.064000                6  \n",
       "2               0.72            0.776        0.054259                2  \n",
       "3               0.68            0.696        0.074189                8  \n",
       "4               0.64            0.656        0.059867               10  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(knn_gridsearch.cv_results_).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gs_df = pd.DataFrame(knn_gridsearch.cv_results_)\n",
    "gs_df = gs_df[gs_df['param_metric'] == 'euclidean']\n",
    "gs_df.plot(x='param_n_neighbors', y='mean_test_score');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Word of Caution on GridSearching\n",
    "\n",
    "`sklearn` models often have many hyperparameters with many different possible values. It may be tempting to search over a wide variety of them. In general, this is not wise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Why not?</summary>\n",
    "\n",
    "- Remember that GridSearch searches over **all possible combinations of hyperparameters in the parameter dictionary!**\n",
    "\n",
    "Imagine that we had this as our parameter dictionary:\n",
    "\n",
    "```python\n",
    "parameter_grid = {\n",
    "    'n_neighbors': range(1, 151),\n",
    "    'weights': ['uniform', 'distance', custom_function],\n",
    "    'algorithm': ['ball_tree', 'kd_tree', 'brute', 'auto'],\n",
    "    'leaf_size': range(1, 152),\n",
    "    'metric': ['minkowski', 'euclidean'],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "```\n",
    "\n",
    "**How many different combinations will need to be tested?**\n",
    "\n",
    "| Parameter | Number of Chosen Values |\n",
    "| --- | --- |\n",
    "| **n_neighbors** | 150 |\n",
    "| **weights** | 3 |\n",
    "| **algorithm** | 4 |\n",
    "| **leaf_size** | 151 |\n",
    "| **metric** | 2 |\n",
    "| **p** | 2 |\n",
    "| <br>_150 \\* 3 \\* 4 \\* 151 \\* 2 \\* 2 = n combinations_ <br><br>| _1,087,200_ |\n",
    "\n",
    "If we select `cv = 5`, we would fit 1,087,200 models on five folds, meaning we fit 5,436,000 models!\n",
    "\n",
    "If you're not careful, GridSearching can quickly scale out of hand computationally.\n",
    "\n",
    "> **It is extremely important to understand what the hyperparameters do and think critically about what ranges are useful and relevant to your model!**\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A brief detour: estimators and transformers.\n",
    "`sklearn` has two types of classes: **estimators** and **transformers**. \n",
    "\n",
    "We've seen several examples of each so far.\n",
    "\n",
    "### Scikit-Learn Estimators\n",
    "Estimators are essentially _models_. They fit this format:\n",
    "\n",
    "```python\n",
    "# Instantiate.\n",
    "model = LinearRegression(params)\n",
    "# Fit.\n",
    "model.fit(X_train, y_train)\n",
    "# Predict.\n",
    "y_pred = model.predict(X_test)\n",
    "```\n",
    "\n",
    "Estimators have a **fit** and **predict** method.\n",
    "\n",
    "### Scikit-Learn Transformers\n",
    "Transformers are not models. They transform your data using similar syntax to estimators. They work like this:\n",
    "\n",
    "```python\n",
    "# Instantiate.\n",
    "ss = StandardScaler(params)\n",
    "# Fit.\n",
    "ss.fit(X_train)\n",
    "# Transform.\n",
    "X_transformed = ss.transform(X_train)\n",
    "```\n",
    "\n",
    "Instead of `fit` and `predict`, they have **fit** and **transform** methods. In fact, since you fit and transform together so often, they have a shortcut:\n",
    "\n",
    "```python\n",
    "ss = StandardScaler(params)\n",
    "X_transformed = ss.fit_transform(X_train)\n",
    "```\n",
    "\n",
    "We've seen a few transformers, including `StandardScaler()` and `PolynomialFeatures()`. There's also `OneHotEncoder()` for dummy encoding and `LabelEncoder()` for factorizing variables. Later we'll see `PCA()`, which is also a transformer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why is this relevant?\n",
    "\n",
    "Check out the [StandardScaler documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html).\n",
    "\n",
    "Transformers may have hyperparameters as well - **but we can't GridSearch over a transformer**! There's no way to get an accuracy (or other) score from just a transformer, since a transformer can't predict!\n",
    "\n",
    "![](./images/grid.jpg)\n",
    "\n",
    "In addition, the acronym ETL, meaning \"extract, transform, load,\" is a very common one in data science. When we gather data from one or more places, there might be **a lot** of preprocessing going on.\n",
    "\n",
    "Oftentimes, we'll want to apply several transformers to a dataset, *then* build a model. \n",
    "- If you do all of these preprocessing steps independently, your code can be messy and it'll be prone to errors!\n",
    "- It can be challenging to consistently recreate this process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines\n",
    "![](./images/pipe.png)\n",
    "\n",
    "Pipelines will allow us to do two things:\n",
    "1. Chain many transformers together before ending in an estimator.\n",
    "2. Allow us to GridSearch over a transformer's hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Pipeline\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a StandardScaler + kNN pipeline.\n",
    "pipe = Pipeline([\n",
    "    ('ss', StandardScaler()),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('ss',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('knn',\n",
       "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                      metric='minkowski', metric_params=None,\n",
       "                                      n_jobs=None, n_neighbors=5, p=2,\n",
       "                                      weights='uniform'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit.\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7619047619047619"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate.\n",
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('ss', StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "  ('knn',\n",
       "   KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                        metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                        weights='uniform'))],\n",
       " 'verbose': False,\n",
       " 'ss': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'knn': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                      metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                      weights='uniform'),\n",
       " 'ss__copy': True,\n",
       " 'ss__with_mean': True,\n",
       " 'ss__with_std': True,\n",
       " 'knn__algorithm': 'auto',\n",
       " 'knn__leaf_size': 30,\n",
       " 'knn__metric': 'minkowski',\n",
       " 'knn__metric_params': None,\n",
       " 'knn__n_jobs': None,\n",
       " 'knn__n_neighbors': 5,\n",
       " 'knn__p': 2,\n",
       " 'knn__weights': 'uniform'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get params - yes, you can GridSearchCV over these!\n",
    "# Notice the naming convention of pipe arguments.\n",
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate pipeline object.\n",
    "pipe_2 = Pipeline([\n",
    "    ('ss', StandardScaler()),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dictionary of hyperparameters.\n",
    "pipe_2_params = {'ss__with_mean': [True, False], \n",
    "                 'ss__with_std': [True, False],\n",
    "                 'knn__p': [1, 2], \n",
    "                 'knn__weights': ['uniform', 'distance'],\n",
    "                 'knn__n_neighbors': [3, 5, 10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate our GridSearchCV object.\n",
    "pipe_2_gridsearch = GridSearchCV(pipe_2, # What is the model we want to fit?\n",
    "                                 pipe_2_params, # What is the dictionary of hyperparameters?\n",
    "                                 cv=5, # What number of folds in CV will we use?\n",
    "                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 240 out of 240 | elapsed:    0.7s finished\n"
     ]
    }
   ],
   "source": [
    "# Fit the GridSearchCV object to the data.\n",
    "pipe_2_gridsearch.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.768"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out best score.\n",
    "pipe_2_gridsearch.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('ss',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('knn',\n",
       "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                      metric='minkowski', metric_params=None,\n",
       "                                      n_jobs=None, n_neighbors=3, p=1,\n",
       "                                      weights='distance'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out best estimator.\n",
    "pipe_2_gridsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best estimator as pipe_2_final.\n",
    "\n",
    "pipe_2_final = pipe_2_gridsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.746031746031746"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the best model on the test data.\n",
    "\n",
    "pipe_2_final.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>What would you conclude from this output?</summary>\n",
    "    \n",
    "- Our model performs slightly better when cross-validated on our training data than on our testing data, but the difference is pretty small.\n",
    "- There may be slight overfitting.\n",
    "- GridSearching gets us the best performing model on the training set; we always have to take care to not overfit!\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interview Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>What is the difference between hyperparameters and statistical parameters?</summary>\n",
    "    \n",
    "- Statistical parameters are quantities that a model can learn or estimate. Examples include $\\beta_0$ and $\\beta_1$ in a linear model.\n",
    "- Hyperparameters are quantities our model cannot learn, but affect the fit of our model. Examples include $k$ in $k$-nearest neighbors and $alpha$ in regularization.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## (BONUS) RandomizedSearchCV + Visualizing Results\n",
    "\n",
    "When you're exploring a particularly high number of different hyperparameters, it can be advantageous to do a randomized search instead of a GridSearch.\n",
    "\n",
    "`from sklearn.model_selection import RandomizedSearchCV`\n",
    "\n",
    "A good blog post on GridSearch, RandomizedSearch, and visualizing the outputs of these methods [can be found here](https://towardsdatascience.com/using-3d-visualizations-to-tune-hyperparameters-of-ml-models-with-python-ba2885eab2e9)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
